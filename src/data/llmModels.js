// LLM model database sourced from https://github.com/AlexsJones/llmfit
// Dataset: hf_models.json (backup from 2026-02-19)

export const LLM_MODELS = [
  { name: "nomic-ai/nomic-embed-text-v1.5", provider: "Nomic", parameter_count: "137M", min_ram_gb: 1.0, recommended_ram_gb: 2.0, min_vram_gb: 0.5, quantization: "F16", context_length: 8192, use_case: "Text embeddings for RAG", architecture: "nomic_bert", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "BAAI/bge-large-en-v1.5", provider: "BAAI", parameter_count: "335M", min_ram_gb: 1.0, recommended_ram_gb: 2.0, min_vram_gb: 0.5, quantization: "Q4_K_M", context_length: 512, use_case: "Text embeddings for RAG", architecture: "bert", hf_downloads: 4887046, hf_likes: 627, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen3-0.6B", provider: "Alibaba", parameter_count: "600M", min_ram_gb: 1.0, recommended_ram_gb: 2.0, min_vram_gb: 0.5, quantization: "Q4_K_M", context_length: 40960, use_case: "Lightweight, edge deployment", architecture: "qwen3", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "google/gemma-3-1b-it", provider: "Google", parameter_count: "1B", min_ram_gb: 1.0, recommended_ram_gb: 2.0, min_vram_gb: 0.5, quantization: "Q4_K_M", context_length: 32768, use_case: "Lightweight, edge deployment", architecture: "gemma3", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "TinyLlama/TinyLlama-1.1B-Chat-v1.0", provider: "Community", parameter_count: "1.1B", min_ram_gb: 1.0, recommended_ram_gb: 2.0, min_vram_gb: 0.6, quantization: "Q4_K_M", context_length: 2048, use_case: "Instruction following, chat", architecture: "llama", hf_downloads: 1770914, hf_likes: 1526, is_moe: false, active_parameters: null },
  { name: "meta-llama/Llama-3.2-1B", provider: "Meta", parameter_count: "1.2B", min_ram_gb: 1.0, recommended_ram_gb: 2.0, min_vram_gb: 0.6, quantization: "Q4_K_M", context_length: 4096, use_case: "General purpose text generation", architecture: "llama", hf_downloads: 1853952, hf_likes: 2293, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen2.5-Coder-1.5B-Instruct", provider: "Alibaba", parameter_count: "1.5B", min_ram_gb: 1.0, recommended_ram_gb: 2.0, min_vram_gb: 0.8, quantization: "Q4_K_M", context_length: 32768, use_case: "Code generation and completion", architecture: "qwen2", hf_downloads: 1501360, hf_likes: 106, is_moe: false, active_parameters: null },
  { name: "stabilityai/stablelm-2-1_6b-chat", provider: "Stability AI", parameter_count: "1.6B", min_ram_gb: 1.0, recommended_ram_gb: 2.0, min_vram_gb: 0.8, quantization: "Q4_K_M", context_length: 4096, use_case: "Instruction following, chat", architecture: "stablelm", hf_downloads: 403, hf_likes: 34, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen3-1.7B", provider: "Alibaba", parameter_count: "1.7B", min_ram_gb: 1.0, recommended_ram_gb: 2.0, min_vram_gb: 0.9, quantization: "Q4_K_M", context_length: 40960, use_case: "Lightweight, edge deployment", architecture: "qwen3", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "google/gemma-2-2b-it", provider: "Google", parameter_count: "2.6B", min_ram_gb: 1.5, recommended_ram_gb: 2.4, min_vram_gb: 1.3, quantization: "Q4_K_M", context_length: 4096, use_case: "General purpose text generation", architecture: "gemma2", hf_downloads: 334622, hf_likes: 1284, is_moe: false, active_parameters: null },
  { name: "ibm-granite/granite-4.0-h-micro", provider: "IBM", parameter_count: "3B", min_ram_gb: 1.7, recommended_ram_gb: 2.8, min_vram_gb: 1.5, quantization: "Q4_K_M", context_length: 131072, use_case: "Enterprise, hybrid Mamba/transformer", architecture: "granite_hybrid", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "meta-llama/Llama-3.2-3B", provider: "Meta", parameter_count: "3.2B", min_ram_gb: 1.8, recommended_ram_gb: 3.0, min_vram_gb: 1.6, quantization: "Q4_K_M", context_length: 4096, use_case: "General purpose text generation", architecture: "llama", hf_downloads: 803855, hf_likes: 697, is_moe: false, active_parameters: null },
  { name: "microsoft/phi-3-mini-4k-instruct", provider: "Microsoft", parameter_count: "3.8B", min_ram_gb: 2.1, recommended_ram_gb: 3.6, min_vram_gb: 2.0, quantization: "Q4_K_M", context_length: 4096, use_case: "Lightweight, edge deployment", architecture: "phi3", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "microsoft/Phi-3.5-mini-instruct", provider: "Microsoft", parameter_count: "3.8B", min_ram_gb: 2.1, recommended_ram_gb: 3.6, min_vram_gb: 2.0, quantization: "Q4_K_M", context_length: 131072, use_case: "Lightweight, long context", architecture: "phi3", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen2.5-VL-3B-Instruct", provider: "Alibaba", parameter_count: "3.8B", min_ram_gb: 2.1, recommended_ram_gb: 3.6, min_vram_gb: 2.0, quantization: "Q4_K_M", context_length: 32768, use_case: "Multimodal, vision and text", architecture: "qwen2_vl", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "microsoft/Phi-4-mini-instruct", provider: "Microsoft", parameter_count: "3.8B", min_ram_gb: 2.1, recommended_ram_gb: 3.6, min_vram_gb: 2.0, quantization: "Q4_K_M", context_length: 131072, use_case: "Lightweight, edge deployment", architecture: "phi4", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "google/gemma-3-4b-it", provider: "Google", parameter_count: "4B", min_ram_gb: 2.2, recommended_ram_gb: 3.7, min_vram_gb: 2.0, quantization: "Q4_K_M", context_length: 131072, use_case: "Lightweight, general purpose", architecture: "gemma3", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen3-4B", provider: "Alibaba", parameter_count: "4.0B", min_ram_gb: 2.2, recommended_ram_gb: 3.7, min_vram_gb: 2.1, quantization: "Q4_K_M", context_length: 40960, use_case: "General purpose text generation", architecture: "qwen3", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "01-ai/Yi-6B-Chat", provider: "01.ai", parameter_count: "6.1B", min_ram_gb: 3.4, recommended_ram_gb: 5.6, min_vram_gb: 3.1, quantization: "Q4_K_M", context_length: 4096, use_case: "Instruction following, chat", architecture: "llama", hf_downloads: 12988, hf_likes: 70, is_moe: false, active_parameters: null },
  { name: "lmsys/vicuna-7b-v1.5", provider: "LMSYS", parameter_count: "7.0B", min_ram_gb: 3.8, recommended_ram_gb: 6.3, min_vram_gb: 3.4, quantization: "Q4_K_M", context_length: 4096, use_case: "Instruction following, chat", architecture: "llama", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "meta-llama/CodeLlama-7b-Instruct-hf", provider: "Meta", parameter_count: "6.7B", min_ram_gb: 3.8, recommended_ram_gb: 6.3, min_vram_gb: 3.5, quantization: "Q4_K_M", context_length: 4096, use_case: "Code generation and completion", architecture: "llama", hf_downloads: 3305, hf_likes: 59, is_moe: false, active_parameters: null },
  { name: "openchat/openchat-3.5-0106", provider: "OpenChat", parameter_count: "7.0B", min_ram_gb: 3.9, recommended_ram_gb: 6.5, min_vram_gb: 3.6, quantization: "Q4_K_M", context_length: 8192, use_case: "Instruction following, chat", architecture: "mistral", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "ibm-granite/granite-4.0-h-tiny", provider: "IBM", parameter_count: "7B", min_ram_gb: 3.9, recommended_ram_gb: 6.5, min_vram_gb: 3.6, quantization: "Q4_K_M", context_length: 131072, use_case: "Enterprise, hybrid Mamba/transformer", architecture: "granite_hybrid", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 1000000000 },
  { name: "microsoft/Orca-2-7b", provider: "Microsoft", parameter_count: "7.0B", min_ram_gb: 3.9, recommended_ram_gb: 6.5, min_vram_gb: 3.6, quantization: "Q4_K_M", context_length: 4096, use_case: "Reasoning, step-by-step solutions", architecture: "llama", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "bigcode/starcoder2-7b", provider: "BigCode", parameter_count: "7.2B", min_ram_gb: 4.0, recommended_ram_gb: 6.7, min_vram_gb: 3.7, quantization: "Q4_K_M", context_length: 16384, use_case: "Code generation and completion", architecture: "starcoder2", hf_downloads: 16730, hf_likes: 209, is_moe: false, active_parameters: null },
  { name: "tiiuae/falcon-7b-instruct", provider: "TII", parameter_count: "7.2B", min_ram_gb: 4.0, recommended_ram_gb: 6.7, min_vram_gb: 3.7, quantization: "Q4_K_M", context_length: 4096, use_case: "Instruction following, chat", architecture: "falcon", hf_downloads: 42085, hf_likes: 1030, is_moe: false, active_parameters: null },
  { name: "HuggingFaceH4/zephyr-7b-beta", provider: "HuggingFace", parameter_count: "7.2B", min_ram_gb: 4.0, recommended_ram_gb: 6.7, min_vram_gb: 3.7, quantization: "Q4_K_M", context_length: 32768, use_case: "General purpose text generation", architecture: "mistral", hf_downloads: 74535, hf_likes: 1833, is_moe: false, active_parameters: null },
  { name: "mistralai/Mistral-7B-Instruct-v0.3", provider: "Mistral AI", parameter_count: "7.2B", min_ram_gb: 4.1, recommended_ram_gb: 6.8, min_vram_gb: 3.7, quantization: "Q4_K_M", context_length: 32768, use_case: "Instruction following, chat", architecture: "mistral", hf_downloads: 1200708, hf_likes: 2419, is_moe: false, active_parameters: null },
  { name: "tiiuae/Falcon3-7B-Instruct", provider: "TII", parameter_count: "7.5B", min_ram_gb: 4.2, recommended_ram_gb: 7.0, min_vram_gb: 3.8, quantization: "Q4_K_M", context_length: 32768, use_case: "Instruction following, chat", architecture: "falcon3", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen2.5-7B-Instruct", provider: "Alibaba", parameter_count: "7.6B", min_ram_gb: 4.3, recommended_ram_gb: 7.1, min_vram_gb: 3.9, quantization: "Q4_K_M", context_length: 32768, use_case: "Instruction following, chat", architecture: "qwen2", hf_downloads: 12751133, hf_likes: 1072, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen2.5-Coder-7B-Instruct", provider: "Alibaba", parameter_count: "7.6B", min_ram_gb: 4.3, recommended_ram_gb: 7.1, min_vram_gb: 3.9, quantization: "Q4_K_M", context_length: 32768, use_case: "Code generation and completion", architecture: "qwen2", hf_downloads: 1372433, hf_likes: 643, is_moe: false, active_parameters: null },
  { name: "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B", provider: "DeepSeek", parameter_count: "7.6B", min_ram_gb: 4.3, recommended_ram_gb: 7.1, min_vram_gb: 3.9, quantization: "Q4_K_M", context_length: 131072, use_case: "Advanced reasoning, chain-of-thought", architecture: "qwen2", hf_downloads: 707158, hf_likes: 787, is_moe: false, active_parameters: null },
  { name: "meta-llama/Llama-3.1-8B", provider: "Meta", parameter_count: "8.0B", min_ram_gb: 4.5, recommended_ram_gb: 7.5, min_vram_gb: 4.1, quantization: "Q4_K_M", context_length: 4096, use_case: "General purpose text generation", architecture: "llama", hf_downloads: 1205931, hf_likes: 2062, is_moe: false, active_parameters: null },
  { name: "meta-llama/Llama-3.1-8B-Instruct", provider: "Meta", parameter_count: "8.0B", min_ram_gb: 4.5, recommended_ram_gb: 7.5, min_vram_gb: 4.1, quantization: "Q4_K_M", context_length: 4096, use_case: "Instruction following, chat", architecture: "llama", hf_downloads: 5713509, hf_likes: 5457, is_moe: false, active_parameters: null },
  { name: "mistralai/Ministral-8B-Instruct-2410", provider: "Mistral AI", parameter_count: "8.0B", min_ram_gb: 4.5, recommended_ram_gb: 7.5, min_vram_gb: 4.1, quantization: "Q4_K_M", context_length: 32768, use_case: "Instruction following, chat", architecture: "mistral", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "ibm-granite/granite-3.1-8b-instruct", provider: "IBM", parameter_count: "8.1B", min_ram_gb: 4.5, recommended_ram_gb: 7.5, min_vram_gb: 4.1, quantization: "Q4_K_M", context_length: 131072, use_case: "Enterprise, instruction following", architecture: "granite", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen3-8B", provider: "Alibaba", parameter_count: "8.2B", min_ram_gb: 4.6, recommended_ram_gb: 7.6, min_vram_gb: 4.2, quantization: "Q4_K_M", context_length: 40960, use_case: "General purpose text generation", architecture: "qwen3", hf_downloads: 4685993, hf_likes: 934, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen2.5-VL-7B-Instruct", provider: "Alibaba", parameter_count: "8.3B", min_ram_gb: 4.6, recommended_ram_gb: 7.7, min_vram_gb: 4.2, quantization: "Q4_K_M", context_length: 32768, use_case: "Multimodal, vision and text", architecture: "qwen2_vl", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "THUDM/glm-4-9b-chat", provider: "Zhipu AI", parameter_count: "9B", min_ram_gb: 5.0, recommended_ram_gb: 8.4, min_vram_gb: 4.6, quantization: "Q4_K_M", context_length: 131072, use_case: "Multilingual, instruction following", architecture: "glm4", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "google/gemma-2-9b-it", provider: "Google", parameter_count: "9.2B", min_ram_gb: 5.2, recommended_ram_gb: 8.6, min_vram_gb: 4.7, quantization: "Q4_K_M", context_length: 4096, use_case: "General purpose text generation", architecture: "gemma2", hf_downloads: 136774, hf_likes: 768, is_moe: false, active_parameters: null },
  { name: "tiiuae/Falcon3-10B-Instruct", provider: "TII", parameter_count: "10.3B", min_ram_gb: 5.8, recommended_ram_gb: 9.6, min_vram_gb: 5.3, quantization: "Q4_K_M", context_length: 32768, use_case: "Instruction following, chat", architecture: "falcon3", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "meta-llama/Llama-3.2-11B-Vision-Instruct", provider: "Meta", parameter_count: "10.7B", min_ram_gb: 6.0, recommended_ram_gb: 9.9, min_vram_gb: 5.5, quantization: "Q4_K_M", context_length: 4096, use_case: "Instruction following, chat", architecture: "mllama", hf_downloads: 170781, hf_likes: 1563, is_moe: false, active_parameters: null },
  { name: "upstage/SOLAR-10.7B-Instruct-v1.0", provider: "Upstage", parameter_count: "10.7B", min_ram_gb: 6.0, recommended_ram_gb: 10.0, min_vram_gb: 5.5, quantization: "Q4_K_M", context_length: 4096, use_case: "High-performance instruction following", architecture: "llama", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "google/gemma-3-12b-it", provider: "Google", parameter_count: "12B", min_ram_gb: 6.7, recommended_ram_gb: 11.2, min_vram_gb: 6.1, quantization: "Q4_K_M", context_length: 131072, use_case: "Multimodal, vision and text", architecture: "gemma3", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "mistralai/Mistral-Nemo-Instruct-2407", provider: "Mistral AI", parameter_count: "12.2B", min_ram_gb: 6.8, recommended_ram_gb: 11.4, min_vram_gb: 6.3, quantization: "Q4_K_M", context_length: 131072, use_case: "Instruction following, chat", architecture: "mistral", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "microsoft/Orca-2-13b", provider: "Microsoft", parameter_count: "13.0B", min_ram_gb: 7.3, recommended_ram_gb: 12.1, min_vram_gb: 6.7, quantization: "Q4_K_M", context_length: 4096, use_case: "Reasoning, step-by-step solutions", architecture: "llama", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "lmsys/vicuna-13b-v1.5", provider: "LMSYS", parameter_count: "13.0B", min_ram_gb: 7.3, recommended_ram_gb: 12.1, min_vram_gb: 6.7, quantization: "Q4_K_M", context_length: 4096, use_case: "Instruction following, chat", architecture: "llama", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "WizardLMTeam/WizardLM-13B-V1.2", provider: "WizardLM", parameter_count: "13.0B", min_ram_gb: 7.3, recommended_ram_gb: 12.1, min_vram_gb: 6.7, quantization: "Q4_K_M", context_length: 4096, use_case: "Instruction following, chat", architecture: "llama", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "meta-llama/CodeLlama-13b-Instruct-hf", provider: "Meta", parameter_count: "13.0B", min_ram_gb: 7.3, recommended_ram_gb: 12.1, min_vram_gb: 6.7, quantization: "Q4_K_M", context_length: 4096, use_case: "Code generation and completion", architecture: "llama", hf_downloads: 3852, hf_likes: 27, is_moe: false, active_parameters: null },
  { name: "microsoft/phi-4", provider: "Microsoft", parameter_count: "14B", min_ram_gb: 7.8, recommended_ram_gb: 13.0, min_vram_gb: 7.2, quantization: "Q4_K_M", context_length: 16384, use_case: "Reasoning, STEM, code generation", architecture: "phi", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "microsoft/Phi-3-medium-14b-instruct", provider: "Microsoft", parameter_count: "14B", min_ram_gb: 7.8, recommended_ram_gb: 13.0, min_vram_gb: 7.2, quantization: "Q4_K_M", context_length: 4096, use_case: "Balanced performance and size", architecture: "phi3", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen2.5-14B-Instruct", provider: "Alibaba", parameter_count: "14.8B", min_ram_gb: 8.2, recommended_ram_gb: 13.7, min_vram_gb: 7.6, quantization: "Q4_K_M", context_length: 131072, use_case: "Instruction following, chat", architecture: "qwen2", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen3-14B", provider: "Alibaba", parameter_count: "14.8B", min_ram_gb: 8.2, recommended_ram_gb: 13.7, min_vram_gb: 7.6, quantization: "Q4_K_M", context_length: 131072, use_case: "General purpose text generation", architecture: "qwen3", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen2.5-Coder-14B-Instruct", provider: "Alibaba", parameter_count: "14.8B", min_ram_gb: 8.3, recommended_ram_gb: 13.8, min_vram_gb: 7.6, quantization: "Q4_K_M", context_length: 32768, use_case: "Code generation and completion", architecture: "qwen2", hf_downloads: 382626, hf_likes: 140, is_moe: false, active_parameters: null },
  { name: "WizardLMTeam/WizardCoder-15B-V1.0", provider: "WizardLM", parameter_count: "15.5B", min_ram_gb: 8.7, recommended_ram_gb: 14.5, min_vram_gb: 7.9, quantization: "Q4_K_M", context_length: 8192, use_case: "Code generation and completion", architecture: "starcoder", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "bigcode/starcoder2-15b", provider: "BigCode", parameter_count: "15.7B", min_ram_gb: 8.8, recommended_ram_gb: 14.6, min_vram_gb: 8.0, quantization: "Q4_K_M", context_length: 16384, use_case: "Code generation and completion", architecture: "starcoder2", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct", provider: "DeepSeek", parameter_count: "16B", min_ram_gb: 8.8, recommended_ram_gb: 14.6, min_vram_gb: 8.0, quantization: "Q4_K_M", context_length: 131072, use_case: "Code generation and completion", architecture: "deepseek_v2", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 2400000000 },
  { name: "inclusionAI/Ling-lite", provider: "Ant Group", parameter_count: "16.8B", min_ram_gb: 9.4, recommended_ram_gb: 15.6, min_vram_gb: 8.6, quantization: "Q4_K_M", context_length: 131072, use_case: "Efficient MoE, general purpose", architecture: "ling", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 2750000000 },
  { name: "mistralai/Mistral-Small-24B-Instruct-2501", provider: "Mistral AI", parameter_count: "24B", min_ram_gb: 13.4, recommended_ram_gb: 22.4, min_vram_gb: 12.3, quantization: "Q4_K_M", context_length: 32768, use_case: "Instruction following, chat", architecture: "mistral", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "mistralai/Mistral-Small-3.1-24B-Instruct-2503", provider: "Mistral AI", parameter_count: "24B", min_ram_gb: 13.4, recommended_ram_gb: 22.4, min_vram_gb: 12.3, quantization: "Q4_K_M", context_length: 131072, use_case: "Multimodal, vision and text", architecture: "mistral", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "google/gemma-3-27b-it", provider: "Google", parameter_count: "27B", min_ram_gb: 15.1, recommended_ram_gb: 25.1, min_vram_gb: 13.8, quantization: "Q4_K_M", context_length: 131072, use_case: "General purpose text generation", architecture: "gemma3", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "google/gemma-2-27b-it", provider: "Google", parameter_count: "27.2B", min_ram_gb: 15.2, recommended_ram_gb: 25.4, min_vram_gb: 13.9, quantization: "Q4_K_M", context_length: 4096, use_case: "General purpose text generation", architecture: "gemma2", hf_downloads: 387056, hf_likes: 559, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen3-30B-A3B", provider: "Alibaba", parameter_count: "30.5B", min_ram_gb: 17.1, recommended_ram_gb: 28.4, min_vram_gb: 15.6, quantization: "Q4_K_M", context_length: 40960, use_case: "Efficient MoE, general purpose", architecture: "qwen3_moe", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 3300000000 },
  { name: "ibm-granite/granite-4.0-h-small", provider: "IBM", parameter_count: "32B", min_ram_gb: 17.9, recommended_ram_gb: 29.8, min_vram_gb: 16.4, quantization: "Q4_K_M", context_length: 131072, use_case: "Enterprise, hybrid Mamba/transformer", architecture: "granite_hybrid", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 9000000000 },
  { name: "allenai/OLMo-2-0325-32B-Instruct", provider: "Allen Institute", parameter_count: "32B", min_ram_gb: 17.9, recommended_ram_gb: 29.8, min_vram_gb: 16.4, quantization: "Q4_K_M", context_length: 4096, use_case: "Fully open-source, instruction following", architecture: "olmo2", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen2.5-32B-Instruct", provider: "Alibaba", parameter_count: "32.5B", min_ram_gb: 18.2, recommended_ram_gb: 30.3, min_vram_gb: 16.7, quantization: "Q4_K_M", context_length: 131072, use_case: "Instruction following, chat", architecture: "qwen2", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen3-32B", provider: "Alibaba", parameter_count: "32.8B", min_ram_gb: 18.3, recommended_ram_gb: 30.5, min_vram_gb: 16.8, quantization: "Q4_K_M", context_length: 40960, use_case: "General purpose text generation", architecture: "qwen3", hf_downloads: 1560791, hf_likes: 654, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen2.5-Coder-32B-Instruct", provider: "Alibaba", parameter_count: "32.8B", min_ram_gb: 18.3, recommended_ram_gb: 30.5, min_vram_gb: 16.8, quantization: "Q4_K_M", context_length: 32768, use_case: "Code generation and completion", architecture: "qwen2", hf_downloads: 734607, hf_likes: 1994, is_moe: false, active_parameters: null },
  { name: "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B", provider: "DeepSeek", parameter_count: "32.8B", min_ram_gb: 18.3, recommended_ram_gb: 30.5, min_vram_gb: 16.8, quantization: "Q4_K_M", context_length: 131072, use_case: "Advanced reasoning, chain-of-thought", architecture: "qwen2", hf_downloads: 1226387, hf_likes: 1515, is_moe: false, active_parameters: null },
  { name: "meta-llama/CodeLlama-34b-Instruct-hf", provider: "Meta", parameter_count: "33.7B", min_ram_gb: 18.9, recommended_ram_gb: 31.4, min_vram_gb: 17.3, quantization: "Q4_K_M", context_length: 4096, use_case: "Code generation and completion", architecture: "llama", hf_downloads: 1067, hf_likes: 18, is_moe: false, active_parameters: null },
  { name: "01-ai/Yi-34B-Chat", provider: "01.ai", parameter_count: "34.4B", min_ram_gb: 19.2, recommended_ram_gb: 32.0, min_vram_gb: 17.6, quantization: "Q4_K_M", context_length: 4096, use_case: "Instruction following, chat", architecture: "llama", hf_downloads: 13208, hf_likes: 357, is_moe: false, active_parameters: null },
  { name: "CohereForAI/c4ai-command-r-v01", provider: "Cohere", parameter_count: "35B", min_ram_gb: 19.5, recommended_ram_gb: 32.6, min_vram_gb: 17.9, quantization: "Q4_K_M", context_length: 131072, use_case: "RAG, tool use, agents", architecture: "cohere", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "tiiuae/falcon-40b-instruct", provider: "TII", parameter_count: "40.0B", min_ram_gb: 22.4, recommended_ram_gb: 37.3, min_vram_gb: 20.5, quantization: "Q4_K_M", context_length: 2048, use_case: "Instruction following, chat", architecture: "falcon", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "mistralai/Mixtral-8x7B-Instruct-v0.1", provider: "Mistral AI", parameter_count: "46.7B", min_ram_gb: 26.1, recommended_ram_gb: 43.5, min_vram_gb: 23.9, quantization: "Q4_K_M", context_length: 32768, use_case: "Instruction following, chat", architecture: "mixtral", hf_downloads: 542837, hf_likes: 4639, is_moe: true, active_parameters: 12900000000 },
  { name: "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO", provider: "NousResearch", parameter_count: "46.7B", min_ram_gb: 26.1, recommended_ram_gb: 43.5, min_vram_gb: 23.9, quantization: "Q4_K_M", context_length: 32768, use_case: "General purpose text generation", architecture: "mixtral", hf_downloads: 8064, hf_likes: 453, is_moe: true, active_parameters: 12900000000 },
  { name: "meta-llama/Llama-3.1-70B-Instruct", provider: "Meta", parameter_count: "70.6B", min_ram_gb: 39.4, recommended_ram_gb: 65.7, min_vram_gb: 36.1, quantization: "Q4_K_M", context_length: 4096, use_case: "Instruction following, chat", architecture: "llama", hf_downloads: 707708, hf_likes: 888, is_moe: false, active_parameters: null },
  { name: "meta-llama/Llama-3.3-70B-Instruct", provider: "Meta", parameter_count: "70.6B", min_ram_gb: 39.4, recommended_ram_gb: 65.7, min_vram_gb: 36.1, quantization: "Q4_K_M", context_length: 131072, use_case: "Instruction following, chat", architecture: "llama", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen2.5-72B-Instruct", provider: "Alibaba", parameter_count: "72.7B", min_ram_gb: 40.6, recommended_ram_gb: 67.7, min_vram_gb: 37.2, quantization: "Q4_K_M", context_length: 32768, use_case: "Instruction following, chat", architecture: "qwen2", hf_downloads: 336890, hf_likes: 910, is_moe: false, active_parameters: null },
  { name: "meta-llama/Llama-4-Scout-17B-16E-Instruct", provider: "Meta", parameter_count: "109B", min_ram_gb: 60.9, recommended_ram_gb: 101.5, min_vram_gb: 55.8, quantization: "Q4_K_M", context_length: 131072, use_case: "Multimodal, vision and text", architecture: "llama4", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 17000000000 },
  { name: "mistralai/Mistral-Large-Instruct-2407", provider: "Mistral AI", parameter_count: "123B", min_ram_gb: 68.7, recommended_ram_gb: 114.6, min_vram_gb: 63.0, quantization: "Q4_K_M", context_length: 131072, use_case: "Large-scale instruction following", architecture: "mistral", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "mistralai/Mixtral-8x22B-Instruct-v0.1", provider: "Mistral AI", parameter_count: "140.6B", min_ram_gb: 78.6, recommended_ram_gb: 130.9, min_vram_gb: 72.0, quantization: "Q4_K_M", context_length: 65536, use_case: "Large MoE, instruction following", architecture: "mixtral", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 39100000000 },
  { name: "rednote-hilab/dots.llm1.inst", provider: "Rednote", parameter_count: "142B", min_ram_gb: 79.3, recommended_ram_gb: 132.2, min_vram_gb: 72.7, quantization: "Q4_K_M", context_length: 131072, use_case: "MoE, general purpose", architecture: "dots", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 14000000000 },
  { name: "bigscience/bloom", provider: "BigScience", parameter_count: "176B", min_ram_gb: 98.3, recommended_ram_gb: 163.9, min_vram_gb: 90.2, quantization: "Q4_K_M", context_length: 2048, use_case: "Multilingual text generation", architecture: "bloom", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "tiiuae/falcon-180B-chat", provider: "TII", parameter_count: "180B", min_ram_gb: 100.6, recommended_ram_gb: 167.6, min_vram_gb: 92.2, quantization: "Q4_K_M", context_length: 2048, use_case: "Large-scale instruction following", architecture: "falcon", hf_downloads: 0, hf_likes: 0, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen3-235B-A22B", provider: "Alibaba", parameter_count: "235B", min_ram_gb: 131.3, recommended_ram_gb: 218.9, min_vram_gb: 120.4, quantization: "Q4_K_M", context_length: 40960, use_case: "State-of-the-art, MoE architecture", architecture: "qwen3_moe", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 22000000000 },
  { name: "baidu/ERNIE-4.5-300B-A47B-Paddle", provider: "Baidu", parameter_count: "300B", min_ram_gb: 167.6, recommended_ram_gb: 279.4, min_vram_gb: 153.7, quantization: "Q4_K_M", context_length: 131072, use_case: "Multilingual, reasoning", architecture: "ernie", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 47000000000 },
  { name: "xai-org/grok-1", provider: "xAI", parameter_count: "314B", min_ram_gb: 175.5, recommended_ram_gb: 292.4, min_vram_gb: 160.8, quantization: "Q4_K_M", context_length: 8192, use_case: "Large MoE, general purpose", architecture: "grok", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 86000000000 },
  { name: "meta-llama/Llama-4-Maverick-17B-128E-Instruct", provider: "Meta", parameter_count: "400B", min_ram_gb: 223.5, recommended_ram_gb: 372.5, min_vram_gb: 204.9, quantization: "Q4_K_M", context_length: 131072, use_case: "Multimodal, vision and text", architecture: "llama4", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 17000000000 },
  { name: "meta-llama/Llama-3.1-405B-Instruct", provider: "Meta", parameter_count: "405.9B", min_ram_gb: 226.8, recommended_ram_gb: 378.0, min_vram_gb: 207.9, quantization: "Q4_K_M", context_length: 4096, use_case: "Instruction following, chat", architecture: "llama", hf_downloads: 147548, hf_likes: 592, is_moe: false, active_parameters: null },
  { name: "Qwen/Qwen3-Coder-480B-A35B-Instruct", provider: "Alibaba", parameter_count: "480B", min_ram_gb: 268.2, recommended_ram_gb: 447.0, min_vram_gb: 245.9, quantization: "Q4_K_M", context_length: 262144, use_case: "Code generation and completion", architecture: "qwen3_moe", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 35000000000 },
  { name: "meituan/LongCat-Flash", provider: "Meituan", parameter_count: "560B", min_ram_gb: 312.9, recommended_ram_gb: 521.5, min_vram_gb: 286.8, quantization: "Q4_K_M", context_length: 524288, use_case: "Long context MoE", architecture: "longcat", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 18600000000 },
  { name: "deepseek-ai/DeepSeek-R1", provider: "DeepSeek", parameter_count: "671B", min_ram_gb: 375.0, recommended_ram_gb: 624.9, min_vram_gb: 343.7, quantization: "Q4_K_M", context_length: 131072, use_case: "Advanced reasoning, chain-of-thought", architecture: "deepseek_v3", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 37000000000 },
  { name: "deepseek-ai/DeepSeek-V3", provider: "DeepSeek", parameter_count: "685B", min_ram_gb: 382.8, recommended_ram_gb: 638.0, min_vram_gb: 351.3, quantization: "Q4_K_M", context_length: 131072, use_case: "State-of-the-art, MoE architecture", architecture: "deepseek_v3", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 37000000000 },
  { name: "moonshotai/Kimi-K2-Instruct", provider: "Moonshot", parameter_count: "1000B", min_ram_gb: 558.8, recommended_ram_gb: 931.3, min_vram_gb: 512.2, quantization: "Q4_K_M", context_length: 131072, use_case: "Large MoE, reasoning", architecture: "kimi", hf_downloads: 0, hf_likes: 0, is_moe: true, active_parameters: 32000000000 },
];
